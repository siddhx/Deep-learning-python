{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 in TF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "display_progress = 40 # after this many batches, output progress to screen\n",
    "wt_init = tf.contrib.layers.xavier_initializer() # weight initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer: \n",
    "n_input = 784\n",
    "\n",
    "# first convolutional layer: \n",
    "n_conv_1 = 32\n",
    "k_conv_1 = 3 # k_size\n",
    "\n",
    "# second convolutional layer: \n",
    "n_conv_2 = 64\n",
    "k_conv_2 = 3\n",
    "\n",
    "# max pooling layer:\n",
    "pool_size = 2\n",
    "mp_layer_dropout = 0.25\n",
    "\n",
    "# dense layer: \n",
    "n_dense = 128\n",
    "dense_layer_dropout = 0.5\n",
    "\n",
    "# output layer: \n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define placeholders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense layer with ReLU activation:\n",
    "def dense(x, W, b):\n",
    "    z = tf.add(tf.matmul(x, W), b)\n",
    "    a = tf.nn.relu(z)\n",
    "    return a\n",
    "\n",
    "# convolutional layer with ReLU activation:\n",
    "def conv2d(x, W, b, stride_length=1):\n",
    "    xW = tf.nn.conv2d(x, W, strides=[1, stride_length, stride_length, 1], padding='SAME')\n",
    "    z = tf.nn.bias_add(xW, b)\n",
    "    a = tf.nn.relu(z)\n",
    "    return a\n",
    "\n",
    "# max-pooling layer: \n",
    "def maxpooling2d(x, p_size):\n",
    "    return tf.nn.max_pool(x, \n",
    "                          ksize=[1, p_size, p_size, 1], \n",
    "                          strides=[1, p_size, p_size, 1], \n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x, weights, biases, n_in, mp_psize, mp_dropout, dense_dropout):\n",
    "\n",
    "    # reshape linear MNIST pixel input into square image: \n",
    "    square_dimensions = int(np.sqrt(n_in))\n",
    "    square_x = tf.reshape(x, shape=[-1, square_dimensions, square_dimensions, 1])\n",
    "    \n",
    "    # convolutional and max-pooling layers:\n",
    "    conv_1 = conv2d(square_x, weights['W_c1'], biases['b_c1'])\n",
    "    conv_2 = conv2d(conv_1, weights['W_c2'], biases['b_c2'])\n",
    "    pool_1 = maxpooling2d(conv_2, mp_psize)\n",
    "    pool_1 = tf.nn.dropout(pool_1, 1-mp_dropout)\n",
    "    \n",
    "    # dense layer: \n",
    "    flat = tf.reshape(pool_1, [-1, weights['W_d1'].get_shape().as_list()[0]])\n",
    "    dense_1 = dense(flat, weights['W_d1'], biases['b_d1'])\n",
    "    dense_1 = tf.nn.dropout(dense_1, 1-dense_dropout)\n",
    "    \n",
    "    # output layer: \n",
    "    out_layer_z = tf.add(tf.matmul(dense_1, weights['W_out']), biases['b_out'])\n",
    "    \n",
    "    return out_layer_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define variable dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super awesome snippet to avoid a nasty error, \n",
    "# on second thought, dont do it, causes more unexpected errors\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "# Define variable dictionaries \n",
    "bias_dict = {\n",
    "    'b_c1': tf.Variable(tf.zeros([n_conv_1])),\n",
    "    'b_c2': tf.Variable(tf.zeros([n_conv_2])),\n",
    "    'b_d1': tf.Variable(tf.zeros([n_dense])),    \n",
    "    'b_out': tf.Variable(tf.zeros([n_classes]))\n",
    "}\n",
    "\n",
    "full_square_length = np.sqrt(n_input)\n",
    "pooled_square_length = int(full_square_length / pool_size)\n",
    "dense_inputs = pooled_square_length**2 * n_conv_2\n",
    "\n",
    "weight_dict = {\n",
    "    'W_c1': tf.get_variable('W_c1', [k_conv_1, k_conv_1, 1, n_conv_1], initializer=wt_init),\n",
    "    'W_c2': tf.get_variable('W_c2', [k_conv_2, k_conv_2, n_conv_1, n_conv_2], initializer=wt_init),\n",
    "    'W_d1': tf.get_variable('W_d1', [dense_inputs, n_dense], initializer=wt_init),    \n",
    "    'W_out': tf.get_variable('W_out', [n_dense, n_classes], initializer=wt_init)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network(x, weight_dict, bias_dict, n_input, pool_size, mp_layer_dropout, dense_layer_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-ce9a472d5c04>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "accuracy_pct = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization Op "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network in session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for  20 epochs.\n",
      "Step 1 of 429 in epoch 1.\n",
      "Step 41 of 429 in epoch 1.\n",
      "Step 81 of 429 in epoch 1.\n",
      "Step 121 of 429 in epoch 1.\n",
      "Step 161 of 429 in epoch 1.\n",
      "Step 201 of 429 in epoch 1.\n",
      "Step 241 of 429 in epoch 1.\n",
      "Step 281 of 429 in epoch 1.\n",
      "Step 321 of 429 in epoch 1.\n",
      "Step 361 of 429 in epoch 1.\n",
      "Step 401 of 429 in epoch 1.\n",
      "Epoch 001: cost =0.246, accuracy = 92.68%\n",
      "Step 1 of 429 in epoch 2.\n",
      "Step 41 of 429 in epoch 2.\n",
      "Step 81 of 429 in epoch 2.\n",
      "Step 121 of 429 in epoch 2.\n",
      "Step 161 of 429 in epoch 2.\n",
      "Step 201 of 429 in epoch 2.\n",
      "Step 241 of 429 in epoch 2.\n",
      "Step 281 of 429 in epoch 2.\n",
      "Step 321 of 429 in epoch 2.\n",
      "Step 361 of 429 in epoch 2.\n",
      "Step 401 of 429 in epoch 2.\n",
      "Epoch 002: cost =0.089, accuracy = 97.33%\n",
      "Step 1 of 429 in epoch 3.\n",
      "Step 41 of 429 in epoch 3.\n",
      "Step 81 of 429 in epoch 3.\n",
      "Step 121 of 429 in epoch 3.\n",
      "Step 161 of 429 in epoch 3.\n",
      "Step 201 of 429 in epoch 3.\n",
      "Step 241 of 429 in epoch 3.\n",
      "Step 281 of 429 in epoch 3.\n",
      "Step 321 of 429 in epoch 3.\n",
      "Step 361 of 429 in epoch 3.\n",
      "Step 401 of 429 in epoch 3.\n",
      "Epoch 003: cost =0.066, accuracy = 98.00%\n",
      "Step 1 of 429 in epoch 4.\n",
      "Step 41 of 429 in epoch 4.\n",
      "Step 81 of 429 in epoch 4.\n",
      "Step 121 of 429 in epoch 4.\n",
      "Step 161 of 429 in epoch 4.\n",
      "Step 201 of 429 in epoch 4.\n",
      "Step 241 of 429 in epoch 4.\n",
      "Step 281 of 429 in epoch 4.\n",
      "Step 321 of 429 in epoch 4.\n",
      "Step 361 of 429 in epoch 4.\n",
      "Step 401 of 429 in epoch 4.\n",
      "Epoch 004: cost =0.054, accuracy = 98.34%\n",
      "Step 1 of 429 in epoch 5.\n",
      "Step 41 of 429 in epoch 5.\n",
      "Step 81 of 429 in epoch 5.\n",
      "Step 121 of 429 in epoch 5.\n",
      "Step 161 of 429 in epoch 5.\n",
      "Step 201 of 429 in epoch 5.\n",
      "Step 241 of 429 in epoch 5.\n",
      "Step 281 of 429 in epoch 5.\n",
      "Step 321 of 429 in epoch 5.\n",
      "Step 361 of 429 in epoch 5.\n",
      "Step 401 of 429 in epoch 5.\n",
      "Epoch 005: cost =0.048, accuracy = 98.50%\n",
      "Step 1 of 429 in epoch 6.\n",
      "Step 41 of 429 in epoch 6.\n",
      "Step 81 of 429 in epoch 6.\n",
      "Step 121 of 429 in epoch 6.\n",
      "Step 161 of 429 in epoch 6.\n",
      "Step 201 of 429 in epoch 6.\n",
      "Step 241 of 429 in epoch 6.\n",
      "Step 281 of 429 in epoch 6.\n",
      "Step 321 of 429 in epoch 6.\n",
      "Step 361 of 429 in epoch 6.\n",
      "Step 401 of 429 in epoch 6.\n",
      "Epoch 006: cost =0.041, accuracy = 98.67%\n",
      "Step 1 of 429 in epoch 7.\n",
      "Step 41 of 429 in epoch 7.\n",
      "Step 81 of 429 in epoch 7.\n",
      "Step 121 of 429 in epoch 7.\n",
      "Step 161 of 429 in epoch 7.\n",
      "Step 201 of 429 in epoch 7.\n",
      "Step 241 of 429 in epoch 7.\n",
      "Step 281 of 429 in epoch 7.\n",
      "Step 321 of 429 in epoch 7.\n",
      "Step 361 of 429 in epoch 7.\n",
      "Step 401 of 429 in epoch 7.\n",
      "Epoch 007: cost =0.036, accuracy = 98.87%\n",
      "Step 1 of 429 in epoch 8.\n",
      "Step 41 of 429 in epoch 8.\n",
      "Step 81 of 429 in epoch 8.\n",
      "Step 121 of 429 in epoch 8.\n",
      "Step 161 of 429 in epoch 8.\n",
      "Step 201 of 429 in epoch 8.\n",
      "Step 241 of 429 in epoch 8.\n",
      "Step 281 of 429 in epoch 8.\n",
      "Step 321 of 429 in epoch 8.\n",
      "Step 361 of 429 in epoch 8.\n",
      "Step 401 of 429 in epoch 8.\n",
      "Epoch 008: cost =0.032, accuracy = 98.92%\n",
      "Step 1 of 429 in epoch 9.\n",
      "Step 41 of 429 in epoch 9.\n",
      "Step 81 of 429 in epoch 9.\n",
      "Step 121 of 429 in epoch 9.\n",
      "Step 161 of 429 in epoch 9.\n",
      "Step 201 of 429 in epoch 9.\n",
      "Step 241 of 429 in epoch 9.\n",
      "Step 281 of 429 in epoch 9.\n",
      "Step 321 of 429 in epoch 9.\n",
      "Step 361 of 429 in epoch 9.\n",
      "Step 401 of 429 in epoch 9.\n",
      "Epoch 009: cost =0.030, accuracy = 99.06%\n",
      "Step 1 of 429 in epoch 10.\n",
      "Step 41 of 429 in epoch 10.\n",
      "Step 81 of 429 in epoch 10.\n",
      "Step 121 of 429 in epoch 10.\n",
      "Step 161 of 429 in epoch 10.\n",
      "Step 201 of 429 in epoch 10.\n",
      "Step 241 of 429 in epoch 10.\n",
      "Step 281 of 429 in epoch 10.\n",
      "Step 321 of 429 in epoch 10.\n",
      "Step 361 of 429 in epoch 10.\n",
      "Step 401 of 429 in epoch 10.\n",
      "Epoch 010: cost =0.026, accuracy = 99.17%\n",
      "Step 1 of 429 in epoch 11.\n",
      "Step 41 of 429 in epoch 11.\n",
      "Step 81 of 429 in epoch 11.\n",
      "Step 121 of 429 in epoch 11.\n",
      "Step 161 of 429 in epoch 11.\n",
      "Step 201 of 429 in epoch 11.\n",
      "Step 241 of 429 in epoch 11.\n",
      "Step 281 of 429 in epoch 11.\n",
      "Step 321 of 429 in epoch 11.\n",
      "Step 361 of 429 in epoch 11.\n",
      "Step 401 of 429 in epoch 11.\n",
      "Epoch 011: cost =0.025, accuracy = 99.17%\n",
      "Step 1 of 429 in epoch 12.\n",
      "Step 41 of 429 in epoch 12.\n",
      "Step 81 of 429 in epoch 12.\n",
      "Step 121 of 429 in epoch 12.\n",
      "Step 161 of 429 in epoch 12.\n",
      "Step 201 of 429 in epoch 12.\n",
      "Step 241 of 429 in epoch 12.\n",
      "Step 281 of 429 in epoch 12.\n",
      "Step 321 of 429 in epoch 12.\n",
      "Step 361 of 429 in epoch 12.\n",
      "Step 401 of 429 in epoch 12.\n",
      "Epoch 012: cost =0.022, accuracy = 99.26%\n",
      "Step 1 of 429 in epoch 13.\n",
      "Step 41 of 429 in epoch 13.\n",
      "Step 81 of 429 in epoch 13.\n",
      "Step 121 of 429 in epoch 13.\n",
      "Step 161 of 429 in epoch 13.\n",
      "Step 201 of 429 in epoch 13.\n",
      "Step 241 of 429 in epoch 13.\n",
      "Step 281 of 429 in epoch 13.\n",
      "Step 321 of 429 in epoch 13.\n",
      "Step 361 of 429 in epoch 13.\n",
      "Step 401 of 429 in epoch 13.\n",
      "Epoch 013: cost =0.023, accuracy = 99.23%\n",
      "Step 1 of 429 in epoch 14.\n",
      "Step 41 of 429 in epoch 14.\n",
      "Step 81 of 429 in epoch 14.\n",
      "Step 121 of 429 in epoch 14.\n",
      "Step 161 of 429 in epoch 14.\n",
      "Step 201 of 429 in epoch 14.\n",
      "Step 241 of 429 in epoch 14.\n",
      "Step 281 of 429 in epoch 14.\n",
      "Step 321 of 429 in epoch 14.\n",
      "Step 361 of 429 in epoch 14.\n",
      "Step 401 of 429 in epoch 14.\n",
      "Epoch 014: cost =0.020, accuracy = 99.33%\n",
      "Step 1 of 429 in epoch 15.\n",
      "Step 41 of 429 in epoch 15.\n",
      "Step 81 of 429 in epoch 15.\n",
      "Step 121 of 429 in epoch 15.\n",
      "Step 161 of 429 in epoch 15.\n",
      "Step 201 of 429 in epoch 15.\n",
      "Step 241 of 429 in epoch 15.\n",
      "Step 281 of 429 in epoch 15.\n",
      "Step 321 of 429 in epoch 15.\n",
      "Step 361 of 429 in epoch 15.\n",
      "Step 401 of 429 in epoch 15.\n",
      "Epoch 015: cost =0.018, accuracy = 99.39%\n",
      "Step 1 of 429 in epoch 16.\n",
      "Step 41 of 429 in epoch 16.\n",
      "Step 81 of 429 in epoch 16.\n",
      "Step 121 of 429 in epoch 16.\n",
      "Step 161 of 429 in epoch 16.\n",
      "Step 201 of 429 in epoch 16.\n",
      "Step 241 of 429 in epoch 16.\n",
      "Step 281 of 429 in epoch 16.\n",
      "Step 321 of 429 in epoch 16.\n",
      "Step 361 of 429 in epoch 16.\n",
      "Step 401 of 429 in epoch 16.\n",
      "Epoch 016: cost =0.018, accuracy = 99.41%\n",
      "Step 1 of 429 in epoch 17.\n",
      "Step 41 of 429 in epoch 17.\n",
      "Step 81 of 429 in epoch 17.\n",
      "Step 121 of 429 in epoch 17.\n",
      "Step 161 of 429 in epoch 17.\n",
      "Step 201 of 429 in epoch 17.\n",
      "Step 241 of 429 in epoch 17.\n",
      "Step 281 of 429 in epoch 17.\n",
      "Step 321 of 429 in epoch 17.\n",
      "Step 361 of 429 in epoch 17.\n",
      "Step 401 of 429 in epoch 17.\n",
      "Epoch 017: cost =0.015, accuracy = 99.50%\n",
      "Step 1 of 429 in epoch 18.\n",
      "Step 41 of 429 in epoch 18.\n",
      "Step 81 of 429 in epoch 18.\n",
      "Step 121 of 429 in epoch 18.\n",
      "Step 161 of 429 in epoch 18.\n",
      "Step 201 of 429 in epoch 18.\n",
      "Step 241 of 429 in epoch 18.\n",
      "Step 281 of 429 in epoch 18.\n",
      "Step 321 of 429 in epoch 18.\n",
      "Step 361 of 429 in epoch 18.\n",
      "Step 401 of 429 in epoch 18.\n",
      "Epoch 018: cost =0.015, accuracy = 99.48%\n",
      "Step 1 of 429 in epoch 19.\n",
      "Step 41 of 429 in epoch 19.\n",
      "Step 81 of 429 in epoch 19.\n",
      "Step 121 of 429 in epoch 19.\n",
      "Step 161 of 429 in epoch 19.\n",
      "Step 201 of 429 in epoch 19.\n",
      "Step 241 of 429 in epoch 19.\n",
      "Step 281 of 429 in epoch 19.\n",
      "Step 321 of 429 in epoch 19.\n",
      "Step 361 of 429 in epoch 19.\n",
      "Step 401 of 429 in epoch 19.\n",
      "Epoch 019: cost =0.016, accuracy = 99.44%\n",
      "Step 1 of 429 in epoch 20.\n",
      "Step 41 of 429 in epoch 20.\n",
      "Step 81 of 429 in epoch 20.\n",
      "Step 121 of 429 in epoch 20.\n",
      "Step 161 of 429 in epoch 20.\n",
      "Step 201 of 429 in epoch 20.\n",
      "Step 241 of 429 in epoch 20.\n",
      "Step 281 of 429 in epoch 20.\n",
      "Step 321 of 429 in epoch 20.\n",
      "Step 361 of 429 in epoch 20.\n",
      "Step 401 of 429 in epoch 20.\n",
      "Epoch 020: cost =0.014, accuracy = 99.52%\n",
      "Training complete. Testing model.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu, W_c2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_1', defined at:\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-474e45e124c3>\", line 1, in <module>\n    predictions = network(x, weight_dict, bias_dict, n_input, pool_size, mp_layer_dropout, dense_layer_dropout)\n  File \"<ipython-input-7-dbae3e7913de>\", line 9, in network\n    conv_2 = conv2d(conv_1, weights['W_c2'], biases['b_c2'])\n  File \"<ipython-input-6-146bde98770b>\", line 9, in conv2d\n    xW = tf.nn.conv2d(x, W, strides=[1, stride_length, stride_length, 1], padding='SAME')\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 717, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu, W_c2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu, W_c2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-54b740bdc5c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training complete. Testing model.\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtest_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mtest_accuracy_pct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_pct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m     \"\"\"\n\u001b[1;32m--> 656\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4899\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4900\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4901\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu, W_c2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_1', defined at:\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-474e45e124c3>\", line 1, in <module>\n    predictions = network(x, weight_dict, bias_dict, n_input, pool_size, mp_layer_dropout, dense_layer_dropout)\n  File \"<ipython-input-7-dbae3e7913de>\", line 9, in network\n    conv_2 = conv2d(conv_1, weights['W_c2'], biases['b_c2'])\n  File \"<ipython-input-6-146bde98770b>\", line 9, in conv2d\n    xW = tf.nn.conv2d(x, W, strides=[1, stride_length, stride_length, 1], padding='SAME')\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 717, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"c:\\users\\siddh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Relu, W_c2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(initializer_op)\n",
    "    \n",
    "    print(\"Training for \", epochs, \"epochs.\")\n",
    "    \n",
    "    #loop over epochs:\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        avg_cost = 0.0\n",
    "        avg_accuracy_pct = 0.0\n",
    "        \n",
    "        #loop over batches\n",
    "        n_batches = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(n_batches):\n",
    "            \n",
    "            # reassurance!\n",
    "            if i % display_progress == 0:\n",
    "                print(\"Step \", i+1, \" of \", n_batches, \" in epoch \", epoch+1, \".\", sep='')\n",
    "            \n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            _, batch_cost, batch_acc = session.run([optimizer, cost, accuracy_pct],\n",
    "                                                  feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "            avg_cost+= batch_cost / n_batches\n",
    "            avg_accuracy_pct+= batch_acc / n_batches\n",
    "        \n",
    "        print(\"Epoch \", '%03d' % (epoch+1),\n",
    "              \": cost =\", '{:.3f}'.format(avg_cost),\n",
    "              \", accuracy = \", '{:.2f}'.format(avg_accuracy_pct), \"%\",\n",
    "                sep='')\n",
    "        \n",
    "    print(\"Training complete. Testing model.\\n\")\n",
    "\n",
    "    test_cost = cost.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "    test_accuracy_pct = accuracy_pct.eval({x: mnist.test.images, y: mnist.test.labels}) \n",
    "\n",
    "    print(\"Test Cost:\", '{:.3f}'.format(test_cost))\n",
    "    print(\"Test Accuracy: \", '{:.2f}'.format(test_accuracy_pct), \"%\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
